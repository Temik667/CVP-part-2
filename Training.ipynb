{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759481d2-6ae3-4b38-8064-a225de8ec741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:36.528407Z",
     "iopub.status.busy": "2024-12-20T15:33:36.527984Z",
     "iopub.status.idle": "2024-12-20T15:33:44.141447Z",
     "shell.execute_reply": "2024-12-20T15:33:44.140651Z",
     "shell.execute_reply.started": "2024-12-20T15:33:36.528368Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc684562-6c2b-404e-8353-5d51b9442330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:44.143268Z",
     "iopub.status.busy": "2024-12-20T15:33:44.142568Z",
     "iopub.status.idle": "2024-12-20T15:33:44.145955Z",
     "shell.execute_reply": "2024-12-20T15:33:44.145207Z",
     "shell.execute_reply.started": "2024-12-20T15:33:44.143246Z"
    }
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "\n",
    "# url = 'https://drive.google.com/file/d/1zNFXjlsSFuUlfsB6lHd_ybe224qmHCUW/view?usp=sharing'\n",
    "# output_path = '/'\n",
    "# gdown.download(url, output_path, quiet=False,fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07883813-2311-4483-8870-d812a666abdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:44.147142Z",
     "iopub.status.busy": "2024-12-20T15:33:44.146658Z",
     "iopub.status.idle": "2024-12-20T15:33:44.153973Z",
     "shell.execute_reply": "2024-12-20T15:33:44.152868Z",
     "shell.execute_reply.started": "2024-12-20T15:33:44.147120Z"
    }
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('/notebooks/Color.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('/notebooks/Transformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f3bf6f-588a-423b-aba0-8741eee5f648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:44.156503Z",
     "iopub.status.busy": "2024-12-20T15:33:44.155882Z",
     "iopub.status.idle": "2024-12-20T15:33:44.491949Z",
     "shell.execute_reply": "2024-12-20T15:33:44.490873Z",
     "shell.execute_reply.started": "2024-12-20T15:33:44.156478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'batch_size': 64, 'name': 'resnet18_color_perception', 'lr': 0.1, 'workers': 4, 'betha_1': 0.9, 'betha_2': 0.999, 'epsilon': 1e-07, 'weight_decay': 0.0001, 'lr_step_size': 30, 'lr_gamma': 0.1, 'total_epochs': 500},\n",
       " 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.name = \"resnet18_color_perception\"\n",
    "        self.lr = 0.1\n",
    "        self.workers = 4\n",
    "        self.betha_1 = 0.9\n",
    "        self.betha_2 = 0.999\n",
    "        self.epsilon = 1e-7\n",
    "        self.weight_decay = 1e-4\n",
    "        self.lr_step_size = 30\n",
    "        self.lr_gamma = 0.1\n",
    "        self.total_epochs = 500\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.__dict__ == other.__dict__\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "params = Params()\n",
    "params, params.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54c4302b-4b09-4032-b899-09996813cce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:44.493696Z",
     "iopub.status.busy": "2024-12-20T15:33:44.493352Z",
     "iopub.status.idle": "2024-12-20T15:33:44.499037Z",
     "shell.execute_reply": "2024-12-20T15:33:44.497999Z",
     "shell.execute_reply.started": "2024-12-20T15:33:44.493663Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_image(image, label):\n",
    "    image = image.permute(1, 2, 0)\n",
    "    plt.imshow(image.squeeze())\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ea7e73-38b8-46ee-9f19-5788715d14a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:44.500175Z",
     "iopub.status.busy": "2024-12-20T15:33:44.499954Z",
     "iopub.status.idle": "2024-12-20T15:33:44.509305Z",
     "shell.execute_reply": "2024-12-20T15:33:44.507131Z",
     "shell.execute_reply.started": "2024-12-20T15:33:44.500155Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "## to get paths and names of each image\n",
    "\n",
    "def images_get_paths(path):\n",
    "    paths = {}\n",
    "    names = {}\n",
    "    rel_paths = ''\n",
    "    for file in os.listdir(path):\n",
    "        if '.' not in file:\n",
    "            for img in os.listdir(path + '/' + file):\n",
    "                rel_paths = path + '/' + file + '/' + os.path.relpath(img)\n",
    "                if file not in paths.keys():\n",
    "                    paths[file] = [rel_paths]\n",
    "                    names[file] = [os.path.relpath(img)]\n",
    "                else:\n",
    "                    paths[file].append(rel_paths)\n",
    "                    names[file].append(os.path.relpath(img))\n",
    "    return paths, names\n",
    "\n",
    "## to organizes files from the given root path into a new structured directory.\n",
    "\n",
    "def organize_files(path):\n",
    "    new_root = os.path.join(\"Dataset\", os.path.basename(path) + \"_organized\")\n",
    "    os.makedirs(new_root, mode=0o777, exist_ok=True)\n",
    "    files_paths, files_names = images_get_paths(path)\n",
    "\n",
    "    for month in files_paths.keys():\n",
    "        month_folder = os.path.join(new_root, month)\n",
    "        os.makedirs(month_folder, mode=0o777, exist_ok=True)\n",
    "        \n",
    "        for name, file_path in zip(files_names[month], files_paths[month]):\n",
    "            category = name.split(\"_\")[0]\n",
    "            category_folder = os.path.join(month_folder, category)\n",
    "            os.makedirs(category_folder, mode=0o777, exist_ok=True)\n",
    "            shutil.move(file_path, os.path.join(category_folder, name))\n",
    "            print(f\"Moved: {file_path} -> {category_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c845a00-76dc-4452-84ab-a81b107d648b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:44.511254Z",
     "iopub.status.busy": "2024-12-20T15:33:44.510908Z",
     "iopub.status.idle": "2024-12-20T15:33:44.517918Z",
     "shell.execute_reply": "2024-12-20T15:33:44.516568Z",
     "shell.execute_reply.started": "2024-12-20T15:33:44.511228Z"
    }
   },
   "outputs": [],
   "source": [
    "## loader for different datasets\n",
    "def Loader_train(root_folder):\n",
    "    train_transformation = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.RandomResizedCrop(224, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
    "            transforms.RandomVerticalFlip(0.2),\n",
    "            transforms.Normalize(mean=[0.485, 0.485, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    train_dataset = torchvision.datasets.ImageFolder(\n",
    "        root = root_folder,\n",
    "        transform = train_transformation\n",
    "    )\n",
    "    train_sampler = torch.utils.data.RandomSampler(train_dataset)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=params.batch_size,\n",
    "        sampler=train_sampler,\n",
    "        num_workers = params.workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc41225-eb30-4c48-a87d-a7dfaf71b613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:44.519958Z",
     "iopub.status.busy": "2024-12-20T15:33:44.519679Z",
     "iopub.status.idle": "2024-12-20T15:33:45.090212Z",
     "shell.execute_reply": "2024-12-20T15:33:45.089276Z",
     "shell.execute_reply.started": "2024-12-20T15:33:44.519933Z"
    }
   },
   "outputs": [],
   "source": [
    "## Validation loader\n",
    "val_transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(size=256, antialias=True),\n",
    "        transforms.CenterCrop(224),\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        transforms.Normalize(mean=[0.485, 0.485, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "val_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='imagenet-mini/val',\n",
    "    transform=val_transformation\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=params.workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1510cf1-cf92-46dd-8bfd-6eb25b63ec21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:45.091676Z",
     "iopub.status.busy": "2024-12-20T15:33:45.091261Z",
     "iopub.status.idle": "2024-12-20T15:33:45.098592Z",
     "shell.execute_reply": "2024-12-20T15:33:45.097828Z",
     "shell.execute_reply.started": "2024-12-20T15:33:45.091633Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def train(dataloader, model, loss_fn, optimizer, epoch, writer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    start0 = time.time()\n",
    "    start = time.time()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_size = len(X)\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * batch_size\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}], {(current/size * 100):>4f}%\")\n",
    "            step = epoch * size + current\n",
    "            writer.add_scalar('training loss',\n",
    "                            loss,\n",
    "                            step)\n",
    "            new_start = time.time()\n",
    "            delta = new_start - start\n",
    "            start = new_start\n",
    "            if batch != 0:\n",
    "                print(\"Done in \", delta, \" seconds\")\n",
    "                remaining_steps = size - current\n",
    "                speed = 100 * batch_size / delta\n",
    "                remaining_time = remaining_steps / speed\n",
    "                print(\"Remaining time (seconds): \", remaining_time)\n",
    "        optimizer.zero_grad()\n",
    "    print(\"Entire epoch done in \", time.time() - start0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "017ef53d-f806-485e-aadb-6977a8cdeb63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:45.101305Z",
     "iopub.status.busy": "2024-12-20T15:33:45.100554Z",
     "iopub.status.idle": "2024-12-20T15:33:45.108527Z",
     "shell.execute_reply": "2024-12-20T15:33:45.107542Z",
     "shell.execute_reply.started": "2024-12-20T15:33:45.101264Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, epoch, writer, train_dataloader, calc_acc5=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, correct_top5 = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            if calc_acc5:\n",
    "                _, pred_top5 = pred.topk(5, 1, largest=True, sorted=True)\n",
    "                correct_top5 += pred_top5.eq(y.view(-1, 1).expand_as(pred_top5)).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    step = epoch * len(train_dataloader.dataset)\n",
    "    if writer != None:\n",
    "        writer.add_scalar('test loss',\n",
    "                            test_loss,\n",
    "                            step)\n",
    "    correct /= size\n",
    "    correct_top5 /= size\n",
    "    if writer != None:\n",
    "        writer.add_scalar('test accuracy',\n",
    "                            100*correct,\n",
    "                            step)\n",
    "        if calc_acc5:\n",
    "            writer.add_scalar('test accuracy5',\n",
    "                            100*correct_top5,\n",
    "                            step)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    if calc_acc5:\n",
    "        print(f\"Test Error: \\n Accuracy-5: {(100*correct_top5):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b389deb7-5b1e-409f-be96-ecb7ad7da3dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:47.373131Z",
     "iopub.status.busy": "2024-12-20T15:33:47.372741Z",
     "iopub.status.idle": "2024-12-20T15:33:47.675668Z",
     "shell.execute_reply": "2024-12-20T15:33:47.674790Z",
     "shell.execute_reply.started": "2024-12-20T15:33:47.373104Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = params.lr, betas = (params.betha_1, params.betha_2),\n",
    "                            eps = params.epsilon, weight_decay = params.weight_decay)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=params.lr_step_size, gamma=params.lr_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2fdb26e-9dfb-40a9-8d49-54ddffe724aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:48.368230Z",
     "iopub.status.busy": "2024-12-20T15:33:48.367889Z",
     "iopub.status.idle": "2024-12-20T15:33:53.941797Z",
     "shell.execute_reply": "2024-12-20T15:33:53.940847Z",
     "shell.execute_reply.started": "2024-12-20T15:33:48.368206Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "resume_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab8c4720-7b9e-4931-b93f-154297b1415c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:33:59.637885Z",
     "iopub.status.busy": "2024-12-20T15:33:59.637585Z",
     "iopub.status.idle": "2024-12-20T15:34:09.614027Z",
     "shell.execute_reply": "2024-12-20T15:34:09.613256Z",
     "shell.execute_reply.started": "2024-12-20T15:33:59.637861Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 15:34:01.708902: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-20 15:34:01.709132: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-20 15:34:01.815544: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-20 15:34:02.055250: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-20 15:34:06.380735: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "\n",
    "start_dataset_idx = 1\n",
    "start_epoch = 1\n",
    "early_stopping_patience = 20\n",
    "no_improvement_count = 0\n",
    "best_val_accuracy = 0\n",
    "\n",
    "checkpoint_path = os.path.join(\"checkpoints\", params.name, f\"checkpoint.pth\")\n",
    "\n",
    "if resume_training and os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler\"])\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "    start_dataset_idx = checkpoint[\"dataset_idx\"]\n",
    "    best_val_accuracy = checkpoint.get(\"best_val_accuracy\", float('inf'))\n",
    "    no_improvement_count = checkpoint.get(\"no_improvement_count\", 0)\n",
    "    assert params == checkpoint[\"params\"]\n",
    "\n",
    "Path(os.path.join(\"checkpoints\", params.name)).mkdir(parents=True, exist_ok=True)\n",
    "writer = SummaryWriter('runs/' + params.name)\n",
    "\n",
    "dataset_root = 'Color'\n",
    "dataset_folders = [os.path.join(dataset_root, f\"color_{i}_months\") for i in range(0, 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab7983-f008-4cc3-b94b-459d708514ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T15:34:09.616106Z",
     "iopub.status.busy": "2024-12-20T15:34:09.615638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on dataset 1 at Color/color_0_months\n",
      "loss: 7.086005  [   64/34745], 0.184199%\n",
      "loss: 6.966100  [ 6464/34745], 18.604116%\n",
      "Done in  17.457796096801758  seconds\n",
      "Remaining time (seconds):  77.1443642833829\n",
      "loss: 6.975791  [12864/34745], 37.024032%\n",
      "Done in  17.970839262008667  seconds\n",
      "Remaining time (seconds):  61.440614670626815\n",
      "loss: 6.974493  [19264/34745], 55.443949%\n",
      "Done in  17.505858659744263  seconds\n",
      "Remaining time (seconds):  42.34503092367202\n",
      "loss: 6.835752  [25664/34745], 73.863865%\n",
      "Done in  17.609616994857788  seconds\n",
      "Remaining time (seconds):  24.98639561410993\n",
      "loss: 7.111526  [32064/34745], 92.283782%\n",
      "Done in  17.573177576065063  seconds\n",
      "Remaining time (seconds):  7.361513918973506\n",
      "Entire epoch done in  106.48897361755371  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 7.027790 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.5%, Avg loss: 7.027790 \n",
      "\n",
      "New best validation accuracy: 0.0010\n",
      "Checkpoint successfully saved at checkpoints/resnet18_color_perception/checkpoint.pth\n",
      "loss: 6.892817  [   64/34745], 0.184199%\n",
      "loss: 6.951437  [ 6464/34745], 18.604116%\n",
      "Done in  16.5672926902771  seconds\n",
      "Remaining time (seconds):  73.2093132146448\n",
      "loss: 6.851079  [12864/34745], 37.024032%\n",
      "Done in  18.583481788635254  seconds\n",
      "Remaining time (seconds):  63.53518203392625\n",
      "loss: 7.052549  [19264/34745], 55.443949%\n",
      "Done in  16.846951484680176  seconds\n",
      "Remaining time (seconds):  40.751196239739656\n",
      "loss: 7.036331  [25664/34745], 73.863865%\n",
      "Done in  14.869117021560669  seconds\n",
      "Remaining time (seconds):  21.097883073873817\n",
      "loss: 6.940333  [32064/34745], 92.283782%\n",
      "Done in  14.908364534378052  seconds\n",
      "Remaining time (seconds):  6.245207080729306\n",
      "Entire epoch done in  89.92175483703613  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 6.996498 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.5%, Avg loss: 6.996498 \n",
      "\n",
      "No improvement for 1 epochs.\n",
      "Checkpoint successfully saved at checkpoints/resnet18_color_perception/checkpoint.pth\n",
      "loss: 6.955247  [   64/34745], 0.184199%\n",
      "loss: 6.992288  [ 6464/34745], 18.604116%\n",
      "Done in  17.861472606658936  seconds\n",
      "Remaining time (seconds):  78.92817293576897\n",
      "loss: 6.895285  [12864/34745], 37.024032%\n",
      "Done in  17.713980197906494  seconds\n",
      "Remaining time (seconds):  60.56243761099875\n",
      "loss: 6.975935  [19264/34745], 55.443949%\n",
      "Done in  16.999877452850342  seconds\n",
      "Remaining time (seconds):  41.12110981993377\n",
      "loss: 6.978949  [25664/34745], 73.863865%\n",
      "Done in  17.72752285003662  seconds\n",
      "Remaining time (seconds):  25.153692968934774\n",
      "loss: 6.945829  [32064/34745], 92.283782%\n",
      "Done in  16.25678777694702  seconds\n",
      "Remaining time (seconds):  6.810070004686714\n",
      "Entire epoch done in  94.83586406707764  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.2%, Avg loss: 7.009767 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.5%, Avg loss: 7.009767 \n",
      "\n",
      "New best validation accuracy: 0.0018\n",
      "Checkpoint successfully saved at checkpoints/resnet18_color_perception/checkpoint.pth\n",
      "loss: 7.007066  [   64/34745], 0.184199%\n",
      "loss: 6.928589  [ 6464/34745], 18.604116%\n",
      "Done in  17.35336470603943  seconds\n",
      "Remaining time (seconds):  76.68289175804703\n",
      "loss: 7.064021  [12864/34745], 37.024032%\n",
      "Done in  17.647958993911743  seconds\n",
      "Remaining time (seconds):  60.336717304028575\n",
      "loss: 6.889684  [19264/34745], 55.443949%\n",
      "Done in  17.546929359436035  seconds\n",
      "Remaining time (seconds):  42.444377095848324\n",
      "loss: 6.925735  [25664/34745], 73.863865%\n",
      "Done in  16.550354480743408  seconds\n",
      "Remaining time (seconds):  23.483401412442326\n",
      "loss: 6.906808  [32064/34745], 92.283782%\n",
      "Done in  15.756857633590698  seconds\n",
      "Remaining time (seconds):  6.600646143071353\n",
      "Entire epoch done in  93.18900227546692  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.2%, Avg loss: 6.995249 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.5%, Avg loss: 6.995249 \n",
      "\n",
      "No improvement for 1 epochs.\n",
      "Checkpoint successfully saved at checkpoints/resnet18_color_perception/checkpoint.pth\n",
      "loss: 6.915059  [   64/34745], 0.184199%\n",
      "loss: 7.022301  [ 6464/34745], 18.604116%\n",
      "Done in  16.668675661087036  seconds\n",
      "Remaining time (seconds):  73.65731505800039\n",
      "loss: 6.966427  [12864/34745], 37.024032%\n",
      "Done in  16.56668996810913  seconds\n",
      "Remaining time (seconds):  56.63995987378061\n",
      "loss: 6.944570  [19264/34745], 55.443949%\n",
      "Done in  16.234248399734497  seconds\n",
      "Remaining time (seconds):  39.26912491817027\n",
      "loss: 7.016630  [25664/34745], 73.863865%\n",
      "Done in  17.66545605659485  seconds\n",
      "Remaining time (seconds):  25.065626007802788\n",
      "loss: 6.940217  [32064/34745], 92.283782%\n",
      "Done in  16.56532859802246  seconds\n",
      "Remaining time (seconds):  6.939319683015347\n",
      "Entire epoch done in  92.19052410125732  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 7.007922 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.5%, Avg loss: 7.007922 \n",
      "\n",
      "No improvement for 2 epochs.\n",
      "Checkpoint successfully saved at checkpoints/resnet18_color_perception/checkpoint.pth\n",
      "loss: 6.923907  [   64/34745], 0.184199%\n",
      "loss: 6.887911  [ 6464/34745], 18.604116%\n",
      "Done in  14.982299089431763  seconds\n",
      "Remaining time (seconds):  66.20537508565933\n",
      "loss: 7.033604  [12864/34745], 37.024032%\n",
      "Done in  17.438830614089966  seconds\n",
      "Remaining time (seconds):  59.62172697920352\n",
      "loss: 6.991641  [19264/34745], 55.443949%\n",
      "Done in  17.004255533218384  seconds\n",
      "Remaining time (seconds):  41.13169998589903\n",
      "loss: 6.983068  [25664/34745], 73.863865%\n",
      "Done in  17.348562240600586  seconds\n",
      "Remaining time (seconds):  24.615983391702176\n",
      "loss: 6.894999  [32064/34745], 92.283782%\n",
      "Done in  16.916276931762695  seconds\n",
      "Remaining time (seconds):  7.086334133446217\n",
      "Entire epoch done in  91.38360023498535  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.2%, Avg loss: 6.993233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.9%, Avg loss: 6.993233 \n",
      "\n",
      "New best validation accuracy: 0.0023\n",
      "Checkpoint successfully saved at checkpoints/resnet18_color_perception/checkpoint.pth\n",
      "loss: 6.910764  [   64/34745], 0.184199%\n",
      "loss: 6.971577  [ 6464/34745], 18.604116%\n",
      "Done in  18.2773756980896  seconds\n",
      "Remaining time (seconds):  80.76600970588625\n",
      "loss: 6.870436  [12864/34745], 37.024032%\n",
      "Done in  17.24921441078186  seconds\n",
      "Remaining time (seconds):  58.97344695661217\n",
      "loss: 6.940494  [19264/34745], 55.443949%\n",
      "Done in  15.091428756713867  seconds\n",
      "Remaining time (seconds):  36.5047513410449\n",
      "loss: 7.005589  [25664/34745], 73.863865%\n",
      "Done in  16.365601062774658  seconds\n",
      "Remaining time (seconds):  23.221253632977604\n",
      "loss: 6.900376  [32064/34745], 92.283782%\n",
      "Done in  17.521331787109375  seconds\n",
      "Remaining time (seconds):  7.339795393943787\n",
      "Entire epoch done in  92.75785112380981  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 6.990098 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.6%, Avg loss: 6.990098 \n",
      "\n",
      "No improvement for 1 epochs.\n",
      "Checkpoint successfully saved at checkpoints/resnet18_color_perception/checkpoint.pth\n",
      "loss: 6.926161  [   64/34745], 0.184199%\n",
      "loss: 7.041225  [ 6464/34745], 18.604116%\n",
      "Done in  15.953780889511108  seconds\n",
      "Remaining time (seconds):  70.49826208379119\n",
      "loss: 6.871420  [12864/34745], 37.024032%\n",
      "Done in  14.916284084320068  seconds\n",
      "Remaining time (seconds):  50.997376882657406\n",
      "loss: 6.994655  [19264/34745], 55.443949%\n",
      "Done in  15.44136118888855  seconds\n",
      "Remaining time (seconds):  37.35120508830994\n",
      "loss: 6.964083  [25664/34745], 73.863865%\n",
      "Done in  15.081222295761108  seconds\n",
      "Remaining time (seconds):  21.398840573094784\n",
      "loss: 6.893218  [32064/34745], 92.283782%\n",
      "Done in  17.682568550109863  seconds\n",
      "Remaining time (seconds):  7.4073384816944605\n",
      "Entire epoch done in  86.73869609832764  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 6.988512 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.6%, Avg loss: 6.988512 \n",
      "\n",
      "No improvement for 2 epochs.\n",
      "Checkpoint successfully saved at checkpoints/resnet18_color_perception/checkpoint.pth\n",
      "loss: 6.975836  [   64/34745], 0.184199%\n",
      "loss: 6.991910  [ 6464/34745], 18.604116%\n",
      "Done in  17.10976505279541  seconds\n",
      "Remaining time (seconds):  75.60644772782922\n",
      "loss: 6.944116  [12864/34745], 37.024032%\n",
      "Done in  17.322646379470825  seconds\n",
      "Remaining time (seconds):  59.22450397331268\n",
      "loss: 6.989555  [19264/34745], 55.443949%\n",
      "Done in  18.325241327285767  seconds\n",
      "Remaining time (seconds):  44.32704077932984\n",
      "loss: 7.015917  [25664/34745], 73.863865%\n",
      "Done in  17.050952434539795  seconds\n",
      "Remaining time (seconds):  24.19370297782123\n",
      "loss: 7.039592  [32064/34745], 92.283782%\n",
      "Done in  18.38840079307556  seconds\n",
      "Remaining time (seconds):  7.703016019724309\n",
      "Entire epoch done in  97.72495889663696  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 6.993917 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.5%, Avg loss: 6.993917 \n",
      "\n",
      "No improvement for 3 epochs.\n",
      "Checkpoint successfully saved at checkpoints/resnet18_color_perception/checkpoint.pth\n",
      "loss: 6.945181  [   64/34745], 0.184199%\n",
      "loss: 6.960032  [ 6464/34745], 18.604116%\n",
      "Done in  16.765509843826294  seconds\n",
      "Remaining time (seconds):  74.08521623332054\n",
      "loss: 6.855379  [12864/34745], 37.024032%\n",
      "Done in  15.197333574295044  seconds\n",
      "Remaining time (seconds):  51.95825874049217\n",
      "loss: 6.886199  [19264/34745], 55.443949%\n",
      "Done in  14.887357950210571  seconds\n",
      "Remaining time (seconds):  36.01112319175154\n",
      "loss: 6.900533  [25664/34745], 73.863865%\n",
      "Done in  15.886784076690674  seconds\n",
      "Remaining time (seconds):  22.541857218816876\n",
      "loss: 7.035007  [32064/34745], 92.283782%\n",
      "Done in  16.907236337661743  seconds\n",
      "Remaining time (seconds):  7.082546972073614\n",
      "Entire epoch done in  89.05953907966614  seconds\n"
     ]
    }
   ],
   "source": [
    "for dataset_idx, dataset_folder in enumerate(dataset_folders, start=1):\n",
    "    if dataset_idx < start_dataset_idx:\n",
    "        continue\n",
    "\n",
    "    print(f\"Training on dataset {dataset_idx} at {dataset_folder}\")\n",
    "    train_loader = Loader_train(dataset_folder)\n",
    "\n",
    "    for epoch in range(start_epoch if dataset_idx == start_dataset_idx else 1, params.total_epochs):\n",
    "        train(train_loader, model, loss_fn, optimizer, epoch, writer)\n",
    "        \n",
    "        val_accuracy = test(val_loader, model, loss_fn, epoch, writer, train_dataloader=train_loader, calc_acc5=True)\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            no_improvement_count = 0\n",
    "            print(f\"New best validation accuracy: {val_accuracy:.4f}\")\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            print(f\"No improvement for {no_improvement_count} epochs.\")\n",
    "\n",
    "        if no_improvement_count >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs with no improvement.\")\n",
    "            break\n",
    "\n",
    "        checkpoint = {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"lr_scheduler\": lr_scheduler.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"dataset_idx\": dataset_idx,\n",
    "            \"params\": params,\n",
    "            \"best_val_accuracy\": best_val_accuracy,\n",
    "            \"no_improvement_count\": no_improvement_count,\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Checkpoint successfully saved at {checkpoint_path}\")\n",
    "        \n",
    "    best_val_accuracy = 0\n",
    "    start_epoch = 1  \n",
    "    no_improvement_count = 0\n",
    "    print(f\"Finished training on dataset {dataset_idx}.\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a54bb-20a0-451a-adc8-4df14f828e67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Standard Training\n",
    "# for epoch in range(start_epoch, 100):\n",
    "#     train(train_loader, model, loss_fn, optimizer, epoch=epoch, writer=writer)\n",
    "#     checkpoint = {\n",
    "#         \"model\": model.state_dict(),\n",
    "#         \"optimizer\": optimizer.state_dict(),\n",
    "#         \"lr_scheduler\": lr_scheduler.state_dict(),\n",
    "#         \"epoch\": epoch,\n",
    "#         \"params\": params\n",
    "#     }\n",
    "#     torch.save(checkpoint, os.path.join(\"checkpoints\", params.name, f\"model_{epoch}.pth\"))\n",
    "#     torch.save(checkpoint, os.path.join(\"checkpoints\", params.name, f\"checkpoint.pth\"))\n",
    "#     lr_scheduler.step()\n",
    "#     test(val_loader, model, loss_fn, epoch + 1, writer, train_dataloader=train_loader, calc_acc5=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
