{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "759481d2-6ae3-4b38-8064-a225de8ec741",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:28:42.446293Z",
     "iopub.status.busy": "2024-12-19T14:28:42.445980Z",
     "iopub.status.idle": "2024-12-19T14:28:42.451136Z",
     "shell.execute_reply": "2024-12-19T14:28:42.450136Z",
     "shell.execute_reply.started": "2024-12-19T14:28:42.446261Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc684562-6c2b-404e-8353-5d51b9442330",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-16T14:51:52.299036Z",
     "iopub.status.busy": "2024-12-16T14:51:52.298698Z",
     "iopub.status.idle": "2024-12-16T14:53:34.285338Z",
     "shell.execute_reply": "2024-12-16T14:53:34.284398Z",
     "shell.execute_reply.started": "2024-12-16T14:51:52.299011Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1zNFXjlsSFuUlfsB6lHd_ybe224qmHCUW\n",
      "From (redirected): https://drive.google.com/uc?id=1zNFXjlsSFuUlfsB6lHd_ybe224qmHCUW&confirm=t&uuid=4b9d7382-0e69-488c-b38e-43d3a3581e8b\n",
      "To: /Color.zip\n",
      "100%|██████████| 9.31G/9.31G [01:37<00:00, 95.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Color.zip'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gdown\n",
    "\n",
    "# url = 'https://drive.google.com/file/d/1zNFXjlsSFuUlfsB6lHd_ybe224qmHCUW/view?usp=sharing'\n",
    "# output_path = '/'\n",
    "# gdown.download(url, output_path, quiet=False,fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07883813-2311-4483-8870-d812a666abdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T15:26:24.663913Z",
     "iopub.status.busy": "2024-12-16T15:26:24.663516Z",
     "iopub.status.idle": "2024-12-16T15:34:07.513901Z",
     "shell.execute_reply": "2024-12-16T15:34:07.511842Z",
     "shell.execute_reply.started": "2024-12-16T15:26:24.663879Z"
    }
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('/notebooks/Color.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('/notebooks/Transformation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f3bf6f-588a-423b-aba0-8741eee5f648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:51:30.178806Z",
     "iopub.status.busy": "2024-12-19T13:51:30.178454Z",
     "iopub.status.idle": "2024-12-19T13:51:30.189025Z",
     "shell.execute_reply": "2024-12-19T13:51:30.187626Z",
     "shell.execute_reply.started": "2024-12-19T13:51:30.178782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'batch_size': 64, 'name': 'resnet18_adam_test', 'lr': 0.1, 'workers': 4, 'betha_1': 0.9, 'betha_2': 0.999, 'epsilon': 1e-07, 'weight_decay': 0.0001, 'lr_step_size': 30, 'lr_gamma': 0.1, 'total_epochs': 2},\n",
       " 64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.name = \"resnet18_color\"\n",
    "        self.lr = 0.1\n",
    "        self.workers = 4\n",
    "        self.betha_1 = 0.9\n",
    "        self.betha_2 = 0.999\n",
    "        self.epsilon = 1e-7\n",
    "        self.weight_decay = 1e-4\n",
    "        self.lr_step_size = 30\n",
    "        self.lr_gamma = 0.1\n",
    "        self.total_epochs = 500\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.__dict__ == other.__dict__\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "params = Params()\n",
    "params, params.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54c4302b-4b09-4032-b899-09996813cce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:51:32.223057Z",
     "iopub.status.busy": "2024-12-19T13:51:32.222734Z",
     "iopub.status.idle": "2024-12-19T13:51:32.227562Z",
     "shell.execute_reply": "2024-12-19T13:51:32.226888Z",
     "shell.execute_reply.started": "2024-12-19T13:51:32.223034Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_image(image, label):\n",
    "    image = image.permute(1, 2, 0)\n",
    "    plt.imshow(image.squeeze())\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52ea7e73-38b8-46ee-9f19-5788715d14a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:51:32.416019Z",
     "iopub.status.busy": "2024-12-19T13:51:32.415469Z",
     "iopub.status.idle": "2024-12-19T13:51:32.424785Z",
     "shell.execute_reply": "2024-12-19T13:51:32.423754Z",
     "shell.execute_reply.started": "2024-12-19T13:51:32.415995Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "## to get paths and names of each image\n",
    "\n",
    "def images_get_paths(path):\n",
    "    paths = {}\n",
    "    names = {}\n",
    "    rel_paths = ''\n",
    "    for file in os.listdir(path):\n",
    "        if '.' not in file:\n",
    "            for img in os.listdir(path + '/' + file):\n",
    "                rel_paths = path + '/' + file + '/' + os.path.relpath(img)\n",
    "                if file not in paths.keys():\n",
    "                    paths[file] = [rel_paths]\n",
    "                    names[file] = [os.path.relpath(img)]\n",
    "                else:\n",
    "                    paths[file].append(rel_paths)\n",
    "                    names[file].append(os.path.relpath(img))\n",
    "    return paths, names\n",
    "\n",
    "## to organizes files from the given root path into a new structured directory.\n",
    "\n",
    "def organize_files(path):\n",
    "    new_root = os.path.join(\"Dataset\", os.path.basename(path) + \"_organized\")\n",
    "    os.makedirs(new_root, mode=0o777, exist_ok=True)\n",
    "    files_paths, files_names = images_get_paths(path)\n",
    "\n",
    "    for month in files_paths.keys():\n",
    "        month_folder = os.path.join(new_root, month)\n",
    "        os.makedirs(month_folder, mode=0o777, exist_ok=True)\n",
    "        \n",
    "        for name, file_path in zip(files_names[month], files_paths[month]):\n",
    "            category = name.split(\"_\")[0]\n",
    "            category_folder = os.path.join(month_folder, category)\n",
    "            os.makedirs(category_folder, mode=0o777, exist_ok=True)\n",
    "            shutil.move(file_path, os.path.join(category_folder, name))\n",
    "            print(f\"Moved: {file_path} -> {category_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c845a00-76dc-4452-84ab-a81b107d648b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:51:32.642454Z",
     "iopub.status.busy": "2024-12-19T13:51:32.642038Z",
     "iopub.status.idle": "2024-12-19T13:51:32.648568Z",
     "shell.execute_reply": "2024-12-19T13:51:32.647395Z",
     "shell.execute_reply.started": "2024-12-19T13:51:32.642429Z"
    }
   },
   "outputs": [],
   "source": [
    "## loader for different datasets\n",
    "def Loader_train(root_folder):\n",
    "    train_transformation = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            # transforms.RandomResizedCrop(224, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.RandomVerticalFlip(0.5),\n",
    "            transforms.Normalize(mean=[0.485, 0.485, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    train_dataset = torchvision.datasets.ImageFolder(\n",
    "        root = root_folder,\n",
    "        transform = train_transformation\n",
    "    )\n",
    "    train_sampler = torch.utils.data.RandomSampler(train_dataset)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=params.batch_size,\n",
    "        sampler=train_sampler,\n",
    "        num_workers = params.workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adc41225-eb30-4c48-a87d-a7dfaf71b613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:51:32.866545Z",
     "iopub.status.busy": "2024-12-19T13:51:32.865620Z",
     "iopub.status.idle": "2024-12-19T13:51:32.902092Z",
     "shell.execute_reply": "2024-12-19T13:51:32.901408Z",
     "shell.execute_reply.started": "2024-12-19T13:51:32.866507Z"
    }
   },
   "outputs": [],
   "source": [
    "## Validation loader\n",
    "val_transformation = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(size=256, antialias=True),\n",
    "        transforms.CenterCrop(224),\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        transforms.Normalize(mean=[0.485, 0.485, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "val_dataset = torchvision.datasets.ImageFolder(\n",
    "    root='imagenet-mini/val',\n",
    "    transform=val_transformation\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=params.workers,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1510cf1-cf92-46dd-8bfd-6eb25b63ec21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:51:33.317969Z",
     "iopub.status.busy": "2024-12-19T13:51:33.317669Z",
     "iopub.status.idle": "2024-12-19T13:51:33.325430Z",
     "shell.execute_reply": "2024-12-19T13:51:33.324508Z",
     "shell.execute_reply.started": "2024-12-19T13:51:33.317947Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def train(dataloader, model, loss_fn, optimizer, epoch, writer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    start0 = time.time()\n",
    "    start = time.time()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_size = len(X)\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * batch_size\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}], {(current/size * 100):>4f}%\")\n",
    "            step = epoch * size + current\n",
    "            writer.add_scalar('training loss',\n",
    "                            loss,\n",
    "                            step)\n",
    "            new_start = time.time()\n",
    "            delta = new_start - start\n",
    "            start = new_start\n",
    "            if batch != 0:\n",
    "                print(\"Done in \", delta, \" seconds\")\n",
    "                remaining_steps = size - current\n",
    "                speed = 100 * batch_size / delta\n",
    "                remaining_time = remaining_steps / speed\n",
    "                print(\"Remaining time (seconds): \", remaining_time)\n",
    "        optimizer.zero_grad()\n",
    "    print(\"Entire epoch done in \", time.time() - start0, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "017ef53d-f806-485e-aadb-6977a8cdeb63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:12:08.192282Z",
     "iopub.status.busy": "2024-12-19T14:12:08.191075Z",
     "iopub.status.idle": "2024-12-19T14:12:08.203134Z",
     "shell.execute_reply": "2024-12-19T14:12:08.202136Z",
     "shell.execute_reply.started": "2024-12-19T14:12:08.192226Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, epoch, writer, train_dataloader, calc_acc5=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, correct_top5 = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            if calc_acc5:\n",
    "                _, pred_top5 = pred.topk(5, 1, largest=True, sorted=True)\n",
    "                correct_top5 += pred_top5.eq(y.view(-1, 1).expand_as(pred_top5)).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    step = epoch * len(train_dataloader.dataset)\n",
    "    if writer != None:\n",
    "        writer.add_scalar('test loss',\n",
    "                            test_loss,\n",
    "                            step)\n",
    "    correct /= size\n",
    "    correct_top5 /= size\n",
    "    if writer != None:\n",
    "        writer.add_scalar('test accuracy',\n",
    "                            100*correct,\n",
    "                            step)\n",
    "        if calc_acc5:\n",
    "            writer.add_scalar('test accuracy5',\n",
    "                            100*correct_top5,\n",
    "                            step)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    if calc_acc5:\n",
    "        print(f\"Test Error: \\n Accuracy-5: {(100*correct_top5):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b389deb7-5b1e-409f-be96-ecb7ad7da3dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:12:10.374503Z",
     "iopub.status.busy": "2024-12-19T14:12:10.374176Z",
     "iopub.status.idle": "2024-12-19T14:12:10.605146Z",
     "shell.execute_reply": "2024-12-19T14:12:10.604375Z",
     "shell.execute_reply.started": "2024-12-19T14:12:10.374480Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = params.lr, betas = (params.betha_1, params.betha_2),\n",
    "                            eps = params.epsilon, weight_decay = params.weight_decay)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=params.lr_step_size, gamma=params.lr_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2fdb26e-9dfb-40a9-8d49-54ddffe724aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:12:11.397402Z",
     "iopub.status.busy": "2024-12-19T14:12:11.396977Z",
     "iopub.status.idle": "2024-12-19T14:12:11.434545Z",
     "shell.execute_reply": "2024-12-19T14:12:11.433411Z",
     "shell.execute_reply.started": "2024-12-19T14:12:11.397377Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "resume_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab8c4720-7b9e-4931-b93f-154297b1415c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:12:13.063328Z",
     "iopub.status.busy": "2024-12-19T14:12:13.063025Z",
     "iopub.status.idle": "2024-12-19T14:12:13.149025Z",
     "shell.execute_reply": "2024-12-19T14:12:13.148245Z",
     "shell.execute_reply.started": "2024-12-19T14:12:13.063305Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "\n",
    "start_dataset_idx = 1\n",
    "start_epoch = 1\n",
    "early_stopping_patience = 10  # Stop if no improvement for 10 epochs\n",
    "no_improvement_count = 0\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "checkpoint_path = os.path.join(\"checkpoints\", params.name, f\"checkpoint.pth\")\n",
    "\n",
    "if resume_training and os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler\"])\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "    start_dataset_idx = checkpoint[\"dataset_idx\"]\n",
    "    best_val_loss = checkpoint.get(\"best_val_loss\", float('inf'))\n",
    "    no_improvement_count = checkpoint.get(\"no_improvement_count\", 0)\n",
    "    assert params == checkpoint[\"params\"]\n",
    "\n",
    "Path(os.path.join(\"checkpoints\", params.name)).mkdir(parents=True, exist_ok=True)\n",
    "writer = SummaryWriter('runs/' + params.name)\n",
    "\n",
    "dataset_root = 'Color'\n",
    "dataset_folders = [os.path.join(dataset_root, f\"color_{i}_months\") for i in range(0, 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51ab7983-f008-4cc3-b94b-459d708514ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T14:12:14.132027Z",
     "iopub.status.busy": "2024-12-19T14:12:14.131735Z",
     "iopub.status.idle": "2024-12-19T14:23:27.370803Z",
     "shell.execute_reply": "2024-12-19T14:23:27.367980Z",
     "shell.execute_reply.started": "2024-12-19T14:12:14.132005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on dataset 1 at Color/color_0_months\n",
      "loss: 7.090174  [   64/34745], 0.184199%\n",
      "loss: 6.891567  [ 6464/34745], 18.604116%\n",
      "Done in  15.603952407836914  seconds\n",
      "Remaining time (seconds):  68.95240281969309\n",
      "loss: 7.071533  [12864/34745], 37.024032%\n",
      "Done in  15.616492986679077  seconds\n",
      "Remaining time (seconds):  53.39132547523827\n",
      "loss: 6.943967  [19264/34745], 55.443949%\n",
      "Done in  15.112584352493286  seconds\n",
      "Remaining time (seconds):  36.55592474389821\n",
      "loss: 6.992158  [25664/34745], 73.863865%\n",
      "Done in  14.926671266555786  seconds\n",
      "Remaining time (seconds):  21.17954715181142\n",
      "loss: 6.911904  [32064/34745], 92.283782%\n",
      "Done in  14.949548244476318  seconds\n",
      "Remaining time (seconds):  6.262459194287658\n",
      "Entire epoch done in  83.91467928886414  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.2%, Avg loss: 7.010909 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.6%, Avg loss: 7.010909 \n",
      "\n",
      "New best validation loss: 7.0109\n",
      "Checkpoint successfully saved at checkpoints/resnet18_adam_test/checkpoint.pth\n",
      "Finished training on dataset 1.\n",
      "Training on dataset 2 at Color/color_1_months\n",
      "loss: 6.939124  [   64/34745], 0.184199%\n",
      "loss: 7.034646  [ 6464/34745], 18.604116%\n",
      "Done in  15.103413820266724  seconds\n",
      "Remaining time (seconds):  66.740569726713\n",
      "loss: 6.984473  [12864/34745], 37.024032%\n",
      "Done in  14.98617672920227  seconds\n",
      "Remaining time (seconds):  51.2363332830742\n",
      "loss: 6.910836  [19264/34745], 55.443949%\n",
      "Done in  15.001087188720703  seconds\n",
      "Remaining time (seconds):  36.28622355759144\n",
      "loss: 7.022706  [25664/34745], 73.863865%\n",
      "Done in  17.191884994506836  seconds\n",
      "Remaining time (seconds):  24.393673067986963\n",
      "loss: 7.119269  [32064/34745], 92.283782%\n",
      "Done in  16.711575746536255  seconds\n",
      "Remaining time (seconds):  7.000583527572453\n",
      "Entire epoch done in  91.39830994606018  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 6.998533 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.6%, Avg loss: 6.998533 \n",
      "\n",
      "New best validation loss: 6.9985\n",
      "Checkpoint successfully saved at checkpoints/resnet18_adam_test/checkpoint.pth\n",
      "Finished training on dataset 2.\n",
      "Training on dataset 3 at Color/color_2_months\n",
      "loss: 6.784960  [   64/34745], 0.184199%\n",
      "loss: 6.879067  [ 6464/34745], 18.604116%\n",
      "Done in  17.630264043807983  seconds\n",
      "Remaining time (seconds):  77.90648397233338\n",
      "loss: 6.991476  [12864/34745], 37.024032%\n",
      "Done in  18.422242164611816  seconds\n",
      "Remaining time (seconds):  62.983918875604864\n",
      "loss: 7.002743  [19264/34745], 55.443949%\n",
      "Done in  17.112218379974365  seconds\n",
      "Remaining time (seconds):  41.39285199068487\n",
      "loss: 6.932169  [25664/34745], 73.863865%\n",
      "Done in  15.197504758834839  seconds\n",
      "Remaining time (seconds):  21.563834486715496\n",
      "loss: 6.993057  [32064/34745], 92.283782%\n",
      "Done in  15.616411209106445  seconds\n",
      "Remaining time (seconds):  6.541812258064747\n",
      "Entire epoch done in  92.11663889884949  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 6.995635 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.5%, Avg loss: 6.995635 \n",
      "\n",
      "New best validation loss: 6.9956\n",
      "Checkpoint successfully saved at checkpoints/resnet18_adam_test/checkpoint.pth\n",
      "Finished training on dataset 3.\n",
      "Training on dataset 4 at Color/color_3_months\n",
      "loss: 6.797350  [   64/34745], 0.184199%\n",
      "loss: 6.932580  [ 6464/34745], 18.604116%\n",
      "Done in  15.300833940505981  seconds\n",
      "Remaining time (seconds):  67.612950729914\n",
      "loss: 6.962968  [12864/34745], 37.024032%\n",
      "Done in  14.983852624893188  seconds\n",
      "Remaining time (seconds):  51.228387388326226\n",
      "loss: 6.929976  [19264/34745], 55.443949%\n",
      "Done in  14.852172374725342  seconds\n",
      "Remaining time (seconds):  35.92601258330047\n",
      "loss: 6.985422  [25664/34745], 73.863865%\n",
      "Done in  14.907769203186035  seconds\n",
      "Remaining time (seconds):  21.152726895958185\n",
      "loss: 6.935466  [32064/34745], 92.283782%\n",
      "Done in  15.41799259185791  seconds\n",
      "Remaining time (seconds):  6.458693459182978\n",
      "Entire epoch done in  83.14608907699585  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 6.999919 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.5%, Avg loss: 6.999919 \n",
      "\n",
      "No improvement for 1 epochs.\n",
      "Checkpoint successfully saved at checkpoints/resnet18_adam_test/checkpoint.pth\n",
      "Finished training on dataset 4.\n",
      "Training on dataset 5 at Color/color_4_months\n",
      "loss: 6.980684  [   64/34745], 0.184199%\n",
      "loss: 6.901648  [ 6464/34745], 18.604116%\n",
      "Done in  15.467737674713135  seconds\n",
      "Remaining time (seconds):  68.35048268415034\n",
      "loss: 6.977422  [12864/34745], 37.024032%\n",
      "Done in  14.848738670349121  seconds\n",
      "Remaining time (seconds):  50.7664454446733\n",
      "loss: 6.978075  [19264/34745], 55.443949%\n",
      "Done in  15.230955362319946  seconds\n",
      "Remaining time (seconds):  36.84225311938673\n",
      "loss: 7.013288  [25664/34745], 73.863865%\n",
      "Done in  15.46318793296814  seconds\n",
      "Remaining time (seconds):  21.940814003013077\n",
      "loss: 6.918221  [32064/34745], 92.283782%\n",
      "Done in  16.208582162857056  seconds\n",
      "Remaining time (seconds):  6.789876371659338\n",
      "Entire epoch done in  85.91389036178589  seconds\n",
      "Test Error: \n",
      " Accuracy: 0.0%, Avg loss: 7.004919 \n",
      "\n",
      "Test Error: \n",
      " Accuracy-5: 0.3%, Avg loss: 7.004919 \n",
      "\n",
      "No improvement for 1 epochs.\n",
      "Checkpoint successfully saved at checkpoints/resnet18_adam_test/checkpoint.pth\n",
      "Finished training on dataset 5.\n",
      "Training on dataset 6 at Color/color_5_months\n",
      "loss: 6.997407  [   64/34694], 0.184470%\n",
      "loss: 6.898530  [ 6464/34694], 18.631464%\n",
      "Done in  16.47896671295166  seconds\n",
      "Remaining time (seconds):  72.68769223541021\n",
      "loss: 6.973768  [12864/34694], 37.078457%\n",
      "Done in  15.046891689300537  seconds\n",
      "Remaining time (seconds):  51.32400712147355\n",
      "loss: 6.887516  [19264/34694], 55.525451%\n",
      "Done in  15.45496129989624  seconds\n",
      "Remaining time (seconds):  37.26094575896859\n",
      "loss: 7.030973  [25664/34694], 73.972445%\n",
      "Done in  15.600666284561157  seconds\n",
      "Remaining time (seconds):  22.011565085873006\n",
      "loss: 6.969899  [32064/34694], 92.419439%\n",
      "Done in  15.459910154342651  seconds\n",
      "Remaining time (seconds):  6.353056829050184\n",
      "Entire epoch done in  86.33293032646179  seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch \u001b[38;5;28;01mif\u001b[39;00m dataset_idx \u001b[38;5;241m==\u001b[39m start_dataset_idx \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m, params\u001b[38;5;241m.\u001b[39mtotal_epochs):\n\u001b[1;32m      9\u001b[0m     train(train_loader, model, loss_fn, optimizer, epoch, writer)\n\u001b[0;32m---> 11\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalc_acc5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_val_loss:\n\u001b[1;32m     14\u001b[0m         best_val_loss \u001b[38;5;241m=\u001b[39m val_loss\n",
      "Cell \u001b[0;32mIn[26], line 7\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(dataloader, model, loss_fn, epoch, writer, train_dataloader, calc_acc5)\u001b[0m\n\u001b[1;32m      5\u001b[0m test_loss, correct, correct_top5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/usr/lib/python3.11/threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dataset_idx, dataset_folder in enumerate(dataset_folders, start=1):\n",
    "    if dataset_idx < start_dataset_idx:\n",
    "        continue\n",
    "\n",
    "    print(f\"Training on dataset {dataset_idx} at {dataset_folder}\")\n",
    "    train_loader = Loader_train(dataset_folder)\n",
    "\n",
    "    for epoch in range(start_epoch if dataset_idx == start_dataset_idx else 1, params.total_epochs):\n",
    "        train(train_loader, model, loss_fn, optimizer, epoch, writer)\n",
    "        \n",
    "        val_loss = test(val_loader, model, loss_fn, epoch, writer, train_dataloader=train_loader, calc_acc5=True)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improvement_count = 0\n",
    "            print(f\"New best validation loss: {val_loss:.4f}\")\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            print(f\"No improvement for {no_improvement_count} epochs.\")\n",
    "\n",
    "        if no_improvement_count >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs with no improvement.\")\n",
    "            break\n",
    "\n",
    "        checkpoint = {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"lr_scheduler\": lr_scheduler.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"dataset_idx\": dataset_idx,\n",
    "            \"params\": params,\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "            \"no_improvement_count\": no_improvement_count,\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Checkpoint successfully saved at {checkpoint_path}\")\n",
    "\n",
    "    start_epoch = 1  \n",
    "    no_improvement_count = 0\n",
    "    print(f\"Finished training on dataset {dataset_idx}.\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a54bb-20a0-451a-adc8-4df14f828e67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Standard Training\n",
    "# for epoch in range(start_epoch, 100):\n",
    "#     train(train_loader, model, loss_fn, optimizer, epoch=epoch, writer=writer)\n",
    "#     checkpoint = {\n",
    "#         \"model\": model.state_dict(),\n",
    "#         \"optimizer\": optimizer.state_dict(),\n",
    "#         \"lr_scheduler\": lr_scheduler.state_dict(),\n",
    "#         \"epoch\": epoch,\n",
    "#         \"params\": params\n",
    "#     }\n",
    "#     torch.save(checkpoint, os.path.join(\"checkpoints\", params.name, f\"model_{epoch}.pth\"))\n",
    "#     torch.save(checkpoint, os.path.join(\"checkpoints\", params.name, f\"checkpoint.pth\"))\n",
    "#     lr_scheduler.step()\n",
    "#     test(val_loader, model, loss_fn, epoch + 1, writer, train_dataloader=train_loader, calc_acc5=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
